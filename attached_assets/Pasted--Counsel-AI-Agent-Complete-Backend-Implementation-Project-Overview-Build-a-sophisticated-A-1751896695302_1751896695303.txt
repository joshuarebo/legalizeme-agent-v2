# Counsel AI Agent - Complete Backend Implementation

## Project Overview
Build a sophisticated AI legal assistant backend for the LegalizeMe platform, specialized for Kenyan jurisdiction with capabilities to:
- Generate detailed legal summaries
- Create jurisdiction-specific documents
- Answer legal queries with context
- Crawl and index Kenyan legal resources
- Integrate multiple AI models (Claude Sonnet 4, Hunyuan-A13B, MiniMax-01)

## Tech Stack
- **Backend**: FastAPI (Python)
- **Database**: PostgreSQL + Vector Database (Chroma/Pinecone)
- **AI Models**: AWS Bedrock (Claude Sonnet 4) + Local/Hugging Face models
- **Web Scraping**: BeautifulSoup4, Scrapy, Selenium
- **Document Processing**: PyPDF2, python-docx, mammoth
- **Search**: Elasticsearch (optional) or vector similarity search
- **Caching**: Redis
- **Authentication**: JWT tokens
- **API Documentation**: Swagger/OpenAPI

## Project Structure
```
counsel-ai-backend/
├── app/
│   ├── __init__.py
│   ├── main.py
│   ├── config.py
│   ├── database.py
│   ├── models/
│   │   ├── __init__.py
│   │   ├── user.py
│   │   ├── document.py
│   │   ├── query.py
│   │   └── legal_case.py
│   ├── services/
│   │   ├── __init__.py
│   │   ├── ai_service.py
│   │   ├── crawler_service.py
│   │   ├── document_service.py
│   │   ├── vector_service.py
│   │   └── mcp_service.py
│   ├── api/
│   │   ├── __init__.py
│   │   ├── routes/
│   │   │   ├── __init__.py
│   │   │   ├── auth.py
│   │   │   ├── counsel.py
│   │   │   ├── documents.py
│   │   │   └── health.py
│   ├── core/
│   │   ├── __init__.py
│   │   ├── security.py
│   │   ├── middleware.py
│   │   └── exceptions.py
│   ├── utils/
│   │   ├── __init__.py
│   │   ├── pdf_parser.py
│   │   ├── text_processor.py
│   │   └── validators.py
│   └── crawlers/
│       ├── __init__.py
│       ├── kenya_law_crawler.py
│       ├── parliament_crawler.py
│       └── base_crawler.py
├── tests/
├── requirements.txt
├── docker-compose.yml
├── Dockerfile
├── .env.example
└── README.md
```

## Implementation Steps

### 1. Environment Setup
Create `.env` file with:
```env
# AWS Bedrock
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_DEFAULT_REGION=us-east-1

# Database
DATABASE_URL=postgresql://username:password@localhost:5432/counsel_db
REDIS_URL=redis://localhost:6379

# Security
SECRET_KEY=your-super-secret-key-here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# AI Models
HUGGING_FACE_TOKEN=your_hf_token
OPENAI_API_KEY=your_openai_key_if_needed

# Crawler Settings
KENYA_LAW_BASE_URL=https://www.kenyalaw.org
PARLIAMENT_BASE_URL=https://parliament.go.ke
CRAWLER_DELAY=2
MAX_CONCURRENT_REQUESTS=5
```

### 2. Requirements File
```txt
fastapi==0.104.1
uvicorn[standard]==0.24.0
sqlalchemy==2.0.23
alembic==1.13.1
psycopg2-binary==2.9.9
redis==5.0.1
pydantic==2.5.0
pydantic-settings==2.1.0
python-multipart==0.0.6
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
httpx==0.25.2
aiofiles==23.2.1
pandas==2.1.3
numpy==1.25.2
scikit-learn==1.3.2
sentence-transformers==2.2.2
chromadb==0.4.18
boto3==1.34.0
botocore==1.34.0
beautifulsoup4==4.12.2
scrapy==2.11.0
selenium==4.15.2
webdriver-manager==4.0.1
PyPDF2==3.0.1
python-docx==1.1.0
mammoth==1.6.0
lxml==4.9.3
requests==2.31.0
celery==5.3.4
transformers==4.36.0
torch==2.1.1
pytest==7.4.3
pytest-asyncio==0.21.1
```

### 3. Main Application (app/main.py)
```python
from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer
import uvicorn
from contextlib import asynccontextmanager

from app.config import settings
from app.database import engine, Base
from app.api.routes import counsel, documents, auth, health
from app.core.middleware import setup_middleware
from app.services.crawler_service import CrawlerService
from app.services.vector_service import VectorService

# Initialize database
Base.metadata.create_all(bind=engine)

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    print("Starting Counsel AI Backend...")
    
    # Initialize services
    crawler_service = CrawlerService()
    vector_service = VectorService()
    
    # Start background tasks
    await crawler_service.start_periodic_crawling()
    
    yield
    
    # Shutdown
    print("Shutting down Counsel AI Backend...")
    await crawler_service.stop_periodic_crawling()

app = FastAPI(
    title="Counsel AI Backend",
    description="AI-powered legal assistant for Kenyan jurisdiction",
    version="1.0.0",
    lifespan=lifespan
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://www.legalizeme.site", "https://legalizeme.site"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Setup custom middleware
setup_middleware(app)

# Include routers
app.include_router(health.router, prefix="/health", tags=["health"])
app.include_router(auth.router, prefix="/auth", tags=["authentication"])
app.include_router(counsel.router, prefix="/counsel", tags=["counsel"])
app.include_router(documents.router, prefix="/documents", tags=["documents"])

@app.get("/")
async def root():
    return {"message": "Counsel AI Backend is running"}

if __name__ == "__main__":
    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=8000,
        reload=True if settings.ENVIRONMENT == "development" else False
    )
```

### 4. AI Service (app/services/ai_service.py)
```python
import boto3
import json
from typing import Dict, List, Optional, Any
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
from sentence_transformers import SentenceTransformer
import httpx

from app.config import settings
from app.models.document import Document
from app.services.vector_service import VectorService

class AIService:
    def __init__(self):
        self.bedrock_client = boto3.client(
            'bedrock-runtime',
            region_name=settings.AWS_DEFAULT_REGION,
            aws_access_key_id=settings.AWS_ACCESS_KEY_ID,
            aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY
        )
        
        self.vector_service = VectorService()
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # Initialize local models
        self.local_models = {}
        self._initialize_local_models()
    
    def _initialize_local_models(self):
        """Initialize local AI models"""
        try:
            # Load Hunyuan model
            self.local_models['hunyuan'] = {
                'tokenizer': AutoTokenizer.from_pretrained('Tencent-Hunyuan/Hunyuan-A13B'),
                'model': AutoModelForCausalLM.from_pretrained('Tencent-Hunyuan/Hunyuan-A13B')
            }
            
            # Load MiniMax model
            self.local_models['minimax'] = {
                'tokenizer': AutoTokenizer.from_pretrained('MiniMax-AI/MiniMax-01'),
                'model': AutoModelForCausalLM.from_pretrained('MiniMax-AI/MiniMax-01')
            }
        except Exception as e:
            print(f"Error loading local models: {e}")
    
    async def generate_legal_summary(self, text: str, context: str = "kenyan_law") -> str:
        """Generate legal summary using Claude Sonnet 4"""
        prompt = f"""
        You are a specialized legal AI assistant for Kenyan jurisdiction. 
        Generate a comprehensive legal summary of the following text:
        
        Context: {context}
        Text: {text}
        
        Please provide:
        1. Key legal issues identified
        2. Relevant Kenyan laws and precedents
        3. Legal implications
        4. Recommended actions
        
        Summary:
        """
        
        try:
            response = self.bedrock_client.invoke_model(
                modelId='anthropic.claude-3-5-sonnet-20241022-v2:0',
                body=json.dumps({
                    'anthropic_version': 'bedrock-2023-05-31',
                    'max_tokens': 4000,
                    'messages': [
                        {
                            'role': 'user',
                            'content': prompt
                        }
                    ]
                })
            )
            
            response_body = json.loads(response['body'].read())
            return response_body['content'][0]['text']
            
        except Exception as e:
            # Fallback to local model
            return await self._generate_with_local_model(prompt, 'hunyuan')
    
    async def answer_legal_query(self, query: str, user_context: Dict = None) -> Dict[str, Any]:
        """Answer legal queries with context from Kenyan law"""
        
        # Get relevant documents from vector store
        relevant_docs = await self.vector_service.search_similar_documents(query, limit=5)
        
        # Build context from relevant documents
        context = "\n\n".join([doc.content for doc in relevant_docs])
        
        prompt = f"""
        You are Counsel, a specialized AI legal assistant for Kenyan jurisdiction.
        
        User Query: {query}
        
        Relevant Legal Context:
        {context}
        
        Please provide a comprehensive answer that includes:
        1. Direct answer to the query
        2. Relevant Kenyan laws and regulations
        3. Case law precedents (if applicable)
        4. Practical legal advice
        5. Links to relevant documents
        
        Answer:
        """
        
        try:
            response = self.bedrock_client.invoke_model(
                modelId='anthropic.claude-3-5-sonnet-20241022-v2:0',
                body=json.dumps({
                    'anthropic_version': 'bedrock-2023-05-31',
                    'max_tokens': 4000,
                    'messages': [
                        {
                            'role': 'user',
                            'content': prompt
                        }
                    ]
                })
            )
            
            response_body = json.loads(response['body'].read())
            answer = response_body['content'][0]['text']
            
            return {
                'answer': answer,
                'relevant_documents': [
                    {
                        'title': doc.title,
                        'url': doc.url,
                        'relevance_score': doc.relevance_score
                    } for doc in relevant_docs
                ],
                'confidence': 0.85  # You can implement confidence scoring
            }
            
        except Exception as e:
            print(f"Error with Bedrock: {e}")
            return await self._fallback_query_response(query, context)
    
    async def generate_legal_document(self, document_type: str, parameters: Dict) -> str:
        """Generate legal documents for Kenyan jurisdiction"""
        
        templates = {
            'contract': 'Generate a legal contract template for Kenyan jurisdiction',
            'agreement': 'Generate a legal agreement template for Kenyan jurisdiction',
            'notice': 'Generate a legal notice template for Kenyan jurisdiction',
            'petition': 'Generate a legal petition template for Kenyan jurisdiction'
        }
        
        prompt = f"""
        Generate a {document_type} document for Kenyan jurisdiction with the following parameters:
        {json.dumps(parameters, indent=2)}
        
        Ensure the document:
        1. Complies with Kenyan law
        2. Includes all necessary legal clauses
        3. Uses appropriate legal language
        4. Has proper formatting
        
        Document:
        """
        
        try:
            response = self.bedrock_client.invoke_model(
                modelId='anthropic.claude-3-5-sonnet-20241022-v2:0',
                body=json.dumps({
                    'anthropic_version': 'bedrock-2023-05-31',
                    'max_tokens': 4000,
                    'messages': [
                        {
                            'role': 'user',
                            'content': prompt
                        }
                    ]
                })
            )
            
            response_body = json.loads(response['body'].read())
            return response_body['content'][0]['text']
            
        except Exception as e:
            return await self._generate_with_local_model(prompt, 'minimax')
    
    async def _generate_with_local_model(self, prompt: str, model_name: str) -> str:
        """Fallback to local models"""
        try:
            if model_name not in self.local_models:
                return "Error: Model not available"
            
            tokenizer = self.local_models[model_name]['tokenizer']
            model = self.local_models[model_name]['model']
            
            inputs = tokenizer.encode(prompt, return_tensors='pt')
            
            with torch.no_grad():
                outputs = model.generate(
                    inputs,
                    max_length=2000,
                    num_return_sequences=1,
                    temperature=0.7,
                    pad_token_id=tokenizer.eos_token_id
                )
            
            response = tokenizer.decode(outputs[0], skip_special_tokens=True)
            return response[len(prompt):].strip()
            
        except Exception as e:
            return f"Error generating response: {str(e)}"
    
    async def _fallback_query_response(self, query: str, context: str) -> Dict[str, Any]:
        """Fallback response when primary AI fails"""
        return {
            'answer': 'I apologize, but I am currently experiencing technical difficulties. Please try again later.',
            'relevant_documents': [],
            'confidence': 0.0
        }
```

### 5. Kenya Law Crawler (app/crawlers/kenya_law_crawler.py)
```python
import asyncio
import aiohttp
from bs4 import BeautifulSoup
from typing import List, Dict, Any
import re
from urllib.parse import urljoin, urlparse
import time
from datetime import datetime
import logging

from app.models.document import Document
from app.services.vector_service import VectorService
from app.utils.pdf_parser import PDFParser
from app.config import settings

class KenyaLawCrawler:
    def __init__(self):
        self.base_url = "https://www.kenyalaw.org"
        self.session = None
        self.vector_service = VectorService()
        self.pdf_parser = PDFParser()
        self.logger = logging.getLogger(__name__)
        
        # Sections to crawl
        self.sections = [
            '/caselaw/cases',
            '/legislation/acts',
            '/legislation/subsidiary',
            '/publications',
            '/gazettes'
        ]
    
    async def start_crawling(self):
        """Start the crawling process"""
        self.session = aiohttp.ClientSession()
        
        try:
            for section in self.sections:
                await self._crawl_section(section)
                await asyncio.sleep(settings.CRAWLER_DELAY)
        finally:
            await self.session.close()
    
    async def _crawl_section(self, section_path: str):
        """Crawl a specific section"""
        url = urljoin(self.base_url, section_path)
        
        try:
            async with self.session.get(url) as response:
                if response.status == 200:
                    html = await response.text()
                    soup = BeautifulSoup(html, 'html.parser')
                    
                    # Extract document links
                    links = await self._extract_document_links(soup, section_path)
                    
                    # Process each document
                    for link in links:
                        await self._process_document(link)
                        await asyncio.sleep(1)  # Rate limiting
                        
        except Exception as e:
            self.logger.error(f"Error crawling {section_path}: {e}")
    
    async def _extract_document_links(self, soup: BeautifulSoup, section: str) -> List[Dict]:
        """Extract document links from page"""
        links = []
        
        # Common selectors for different sections
        selectors = {
            '/caselaw/cases': 'a[href*="/caselaw/cases/"]',
            '/legislation/acts': 'a[href*="/legislation/acts/"]',
            '/legislation/subsidiary': 'a[href*="/legislation/subsidiary/"]',
            '/publications': 'a[href*="/publications/"]',
            '/gazettes': 'a[href*="/gazettes/"]'
        }
        
        selector = selectors.get(section, 'a[href*=".pdf"], a[href*="/case/"], a[href*="/act/"]')
        
        for link in soup.select(selector):
            href = link.get('href')
            if href:
                full_url = urljoin(self.base_url, href)
                title = link.get_text(strip=True)
                
                links.append({
                    'url': full_url,
                    'title': title,
                    'section': section
                })
        
        return links
    
    async def _process_document(self, link_info: Dict):
        """Process individual document"""
        url = link_info['url']
        title = link_info['title']
        section = link_info['section']
        
        try:
            async with self.session.get(url) as response:
                if response.status == 200:
                    content_type = response.headers.get('content-type', '')
                    
                    if 'pdf' in content_type:
                        # Handle PDF documents
                        pdf_content = await response.read()
                        text_content = await self.pdf_parser.extract_text_from_pdf(pdf_content)
                    else:
                        # Handle HTML documents
                        html_content = await response.text()
                        text_content = await self._extract_text_from_html(html_content)
                    
                    # Create document object
                    document = Document(
                        title=title,
                        content=text_content,
                        url=url,
                        document_type=self._get_document_type(section),
                        jurisdiction='kenya',
                        crawled_at=datetime.now(),
                        metadata={
                            'section': section,
                            'word_count': len(text_content.split())
                        }
                    )
                    
                    # Store in vector database
                    await self.vector_service.store_document(document)
                    
        except Exception as e:
            self.logger.error(f"Error processing document {url}: {e}")
    
    async def _extract_text_from_html(self, html: str) -> str:
        """Extract clean text from HTML"""
        soup = BeautifulSoup(html, 'html.parser')
        
        # Remove script and style elements
        for script in soup(["script", "style"]):
            script.decompose()
        
        # Extract text
        text = soup.get_text()
        
        # Clean up text
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = ' '.join(chunk for chunk in chunks if chunk)
        
        return text
    
    def _get_document_type(self, section: str) -> str:
        """Determine document type from section"""
        type_mapping = {
            '/caselaw/cases': 'case_law',
            '/legislation/acts': 'legislation',
            '/legislation/subsidiary': 'subsidiary_legislation',
            '/publications': 'publication',
            '/gazettes': 'gazette'
        }
        
        return type_mapping.get(section, 'unknown')
```

### 6. API Routes (app/api/routes/counsel.py)
```python
from fastapi import APIRouter, HTTPException, Depends, BackgroundTasks
from pydantic import BaseModel
from typing import Dict, List, Optional, Any
import json

from app.services.ai_service import AIService
from app.services.vector_service import VectorService
from app.core.security import get_current_user
from app.models.user import User

router = APIRouter()

class QueryRequest(BaseModel):
    query: str
    context: Optional[Dict] = None
    user_id: Optional[str] = None

class SummaryRequest(BaseModel):
    text: str
    context: Optional[str] = "kenyan_law"
    summary_type: Optional[str] = "detailed"

class DocumentRequest(BaseModel):
    document_type: str
    parameters: Dict[str, Any]
    jurisdiction: Optional[str] = "kenya"

class ChatMessage(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    messages: List[ChatMessage]
    context: Optional[Dict] = None

# Initialize services
ai_service = AIService()
vector_service = VectorService()

@router.post("/query")
async def ask_counsel(
    request: QueryRequest,
    current_user: User = Depends(get_current_user)
):
    """Ask Counsel AI a legal question"""
    try:
        response = await ai_service.answer_legal_query(
            query=request.query,
            user_context=request.context
        )
        
        return {
            "success": True,
            "data": response,
            "user_id": current_user.id
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error processing query: {str(e)}")

@router.post("/summarize")
async def generate_summary(
    request: SummaryRequest,
    current_user: User = Depends(get_current_user)
):
    """Generate legal summary"""
    try:
        summary = await ai_service.generate_legal_summary(
            text=request.text,
            context=request.context
        )
        
        return {
            "success": True,
            "data": {
                "summary": summary,
                "word_count": len(summary.split()),
                "original_length": len(request.text.split())
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error generating summary: {str(e)}")

@router.post("/generate-document")
async def generate_document(
    request: DocumentRequest,
    current_user: User = Depends(get_current_user)
):
    """Generate legal document"""
    try:
        document = await ai_service.generate_legal_document(
            document_type=request.document_type,
            parameters=request.parameters
        )
        
        return {
            "success": True,
            "data": {
                "document": document,
                "document_type": request.document_type,
                "generated_at": datetime.now().isoformat()
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error generating document: {str(e)}")

@router.post("/chat")
async def chat_with_counsel(
    request: ChatRequest,
    current_user: User = Depends(get_current_user)
):
    """Chat interface with Counsel AI"""
    try:
        # Get the last user message
        user_message = request.messages[-1].content if request.messages else ""
        
        # Generate response
        response = await ai_service.answer_legal_query(
            query=user_message,
            user_context=request.context
        )
        
        return {
            "success": True,
            "data": {
                "message": response['answer'],
                "sources": response['relevant_documents'],
                "confidence": response['confidence']
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error in chat: {str(e)}")

@router.get("/search")
async def search_legal_documents(
    query: str,
    limit: int = 10,
    current_user: User = Depends(get_current_user)
):
    """Search legal documents"""
    try:
        documents = await vector_service.search_similar_documents(
            query=query,
            limit=limit
        )
        
        return {
            "success": True,
            "data": {
                "documents": [
                    {
                        "title": doc.title,
                        "url": doc.url,
                        "snippet": doc.content[:200] + "..." if len(doc.content) > 200 else doc.content,
                        "relevance_score": doc.relevance_score,
                        "document_type": doc.document_type
                    }
                    for doc in documents
                ],
                "total_results": len(documents)
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error searching documents: {str(e)}")

@router.get("/models/status")
async def get_model_status(
    current_user: User = Depends(get_current_user)
):
    """Get status of AI models"""
    try:
        # Check model availability
        bedrock_status = await ai_service.check_bedrock_status()
        local_models_status = await ai_service.check_local_models_status()
        
        return {
            "success": True,
            "data": {
                "bedrock": bedrock_status,
                "local_models": local_models_status,
                "timestamp": datetime.now().isoformat()
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error checking model status: {str(e)}")
```

### 7. Docker Configuration
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    make \
    libffi-dev \
    libssl-dev \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for better caching
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create non-root user
RUN adduser --disabled-password --gecos '' appuser
RUN chown -R appuser:appuser /app
USER appuser

# Expose port
EXPOSE 8000

# Run the application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 8. Docker Compose
```yaml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/counsel_db
      - REDIS_URL=redis://redis:6379
    depends_on:
      - db
      - redis
    volumes:
      - ./app:/app/app
    env_file:
      - .env

  db:
    image: postgres:15
    environment:
      - POSTGRES_DB=counsel_db
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  worker:
    build: .
    command: celery -A app.tasks worker --loglevel=info
    depends_on:
      - redis
      - db
    env_file:
      - .env

volumes:
  postgres_data:
```

### 9. Testing Configuration
```python
# tests/test_counsel.py
import pytest
from httpx import AsyncClient
from app.main import app

@pytest.fixture
async def client():
    async with AsyncClient(app=app, base_url="http://test") as ac:
        yield ac

@pytest.mark.asyncio
async def test_health_check(client):
    response = await client.get("/health/")
    assert response.status_code == 200
    assert response.json()["status"] == "healthy"

@pytest.mark.asyncio
async def test_counsel_query(client):
    # Mock authentication
    headers = {"Authorization": "Bearer test-token"}
    
    response = await client.post(
        "/counsel/query",
        json={"query": "What are the requirements for forming a company in Kenya?"},
        headers=headers
    )
    
    assert response.status_code == 200
    assert "answer" in response.json()["data"]
```

### 10. Deployment Instructions

1. **Clone and Setup:**
```bash
git clone <your-repo>
cd counsel-ai-backend
cp .env.example .env
# Edit .env with your credentials
```

2. **Local Development:**
```bash
# Install dependencies
pip install -r requirements.txt

# Run migrations
alembic upgrade head

# Start the server
uvicorn app.main:app --reload
```

3. **Docker Deployment:**
```bash
# Build and run
docker-compose up --build

# Run in production
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d
```

4. **API Endpoints:**
- `POST /counsel/query` - Ask legal questions
- `POST /counsel/summarize` - Generate summaries
- `POST /counsel/